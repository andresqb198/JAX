{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29f5381-1ff7-48c8-a8eb-1384d29240c0",
   "metadata": {},
   "source": [
    "# Training a simple neural network with tensorflow/ datasets Data Loading\n",
    "https://jax.readthedocs.io/en/latest/notebooks/neural_network_with_tfds_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3e47a3-8be6-4422-8dc2-8f249194536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0170ab7-0767-4730-bcc0-0f8848b746de",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae4c4d2-3f57-4503-a8e2-c1c6c820ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "\n",
    "def random_layer_params(m,n,key,scale=1e-2):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale*random.normal(w_key,(n,m)) , scale * random.normal(b_key,(n,))\n",
    "\n",
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m,n,k) for m,n,k in zip(sizes[:-1],sizes[1:],keys)]\n",
    "\n",
    "layer_sizes = [784,512,512,10]\n",
    "step_size = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "n_targets = 10\n",
    "params = init_network_params(layer_sizes, random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee005a2-6d4f-4478-b1c1-61371caa0008",
   "metadata": {},
   "source": [
    "## Auto-batching predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99233ee9-aab2-4f6e-b4ed-3f696e22bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "def relu(x):\n",
    "    return jnp.maximum(0,x)\n",
    "\n",
    "def predict(params, image):\n",
    "    # per-example predictions\n",
    "    activations = image\n",
    "    for w,b in params[:-1]:\n",
    "        outputs = jnp.dot(w,activations)+b\n",
    "        activations = relu(outputs)\n",
    "    \n",
    "    final_w, final_b = params[-1]\n",
    "    logits = jnp.dot(final_w,activations) +  final_b\n",
    "    return logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f6f48f-34e4-4b85-a41a-8fab6822b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# This works on single examples\n",
    "random_flattened_image =  random.normal(random.PRNGKey(1),(28*28,))\n",
    "preds = predict(params, random_flattened_image)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38e63fc1-d933-4052-9ba1-0c745d83615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid shapes!\n"
     ]
    }
   ],
   "source": [
    "# Doesn't work with a batch\n",
    "random_flattened_images = random.normal(random.PRNGKey(1),(10,28*28))\n",
    "try:\n",
    "    preds = predict(params, random_flattened_images)\n",
    "except TypeError:\n",
    "    print(\"Invalid shapes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f0bf61-f069-4c49-bc1f-13152e722cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "# Let's upgrade it to handle batches using vmap\n",
    "\n",
    "# make a batched version of the predict function\n",
    "batched_predict = vmap(predict, in_axes = (None,0))\n",
    "\n",
    "# batched_predict has the same call signature as predict\n",
    "batched_preds = batched_predict(params, random_flattened_images)\n",
    "print(batched_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c12a2a-7d38-44e9-b7bd-83a33a20ba84",
   "metadata": {},
   "source": [
    "At this point, we have all the ingredients we need to define our neural network and train it. Weâ€™ve built an auto-batched version of predict, which we should be able to use in a loss function. We should be able to use grad to take the derivative of the loss with respect to the neural network parameters. Last, we should be able to use jit to speed up everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9a46e-1de7-4bd8-b442-a6687c63e53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
